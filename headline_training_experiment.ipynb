{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headline Generation Training Experiment\n",
    "\n",
    "This notebook demonstrates how to use the modular training pipeline for headline generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if running in a new environment\n",
    "# !pip install torch transformers datasets rouge-score nltk streamlit bitsandbytes trl peft flash-attn huggingface-hub pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('./src')\n",
    "\n",
    "# Import our modules\n",
    "from src import (\n",
    "    load_dataset,\n",
    "    train_headline_model,\n",
    "    quick_train,\n",
    "    load_trained_model,\n",
    "    generate_headlines,\n",
    "    setup_model_and_tokenizer\n",
    ")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "train_df, val_df = load_dataset()\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(\"\\nTraining data sample:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze article and headline lengths\n",
    "train_df['article_length'] = train_df['article'].str.len()\n",
    "train_df['headline_length'] = train_df['headline'].str.len()\n",
    "train_df['article_words'] = train_df['article'].str.split().str.len()\n",
    "train_df['headline_words'] = train_df['headline'].str.split().str.len()\n",
    "\n",
    "print(\"Article statistics:\")\n",
    "print(train_df[['article_length', 'article_words']].describe())\n",
    "print(\"\\nHeadline statistics:\")\n",
    "print(train_df[['headline_length', 'headline_words']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize length distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Article length distribution\n",
    "axes[0, 0].hist(train_df['article_length'], bins=50, alpha=0.7)\n",
    "axes[0, 0].set_title('Article Length Distribution (characters)')\n",
    "axes[0, 0].set_xlabel('Length')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Headline length distribution\n",
    "axes[0, 1].hist(train_df['headline_length'], bins=50, alpha=0.7, color='orange')\n",
    "axes[0, 1].set_title('Headline Length Distribution (characters)')\n",
    "axes[0, 1].set_xlabel('Length')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Article word count distribution\n",
    "axes[1, 0].hist(train_df['article_words'], bins=50, alpha=0.7, color='green')\n",
    "axes[1, 0].set_title('Article Word Count Distribution')\n",
    "axes[1, 0].set_xlabel('Word Count')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Headline word count distribution\n",
    "axes[1, 1].hist(train_df['headline_words'], bins=30, alpha=0.7, color='red')\n",
    "axes[1, 1].set_title('Headline Word Count Distribution')\n",
    "axes[1, 1].set_xlabel('Word Count')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some example article-headline pairs\n",
    "print(\"Sample article-headline pairs:\\n\")\n",
    "for i in range(3):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Article: {train_df.iloc[i]['article'][:200]}...\")\n",
    "    print(f\"Headline: {train_df.iloc[i]['headline']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration and Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "training_config = {\n",
    "    \"model_id\": \"Helsinki-NLP/opus-mt-en-mul\",\n",
    "    \"output_dir\": \"./models/headline-generator-experiment\",\n",
    "    \"hub_model_name\": \"headline-generator-opus-mt-en-mul-qlora-sft-v2\",\n",
    "    \n",
    "    # Training parameters\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 128,\n",
    "    \"learning_rate\": 2.0e-05,\n",
    "    \n",
    "    # LoRA parameters\n",
    "    \"lora_r\": 64,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \n",
    "    # Other settings\n",
    "    \"max_length\": 256,\n",
    "    \"fp16\": True,\n",
    "    \"seed\": 42,\n",
    "    \n",
    "    # Hub upload\n",
    "    \"push_to_hub_after_training\": False  # Set to True to push to hub\n",
    "}\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"Starting training with the configured parameters...\")\n",
    "\n",
    "try:\n",
    "    trainer, metrics = train_headline_model(**training_config)\n",
    "    print(\"\\nTraining completed successfully!\")\n",
    "    print(f\"Final training metrics: {metrics}\")\n",
    "except Exception as e:\n",
    "    print(f\"Training failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model_path = training_config[\"output_dir\"]\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Loading trained model from: {model_path}\")\n",
    "    model, tokenizer = load_trained_model(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "else:\n",
    "    print(f\"Model path {model_path} does not exist. Training may have failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with some examples from the validation set\n",
    "test_articles = val_df['article'].head(5).tolist()\n",
    "true_headlines = val_df['headline'].head(5).tolist()\n",
    "\n",
    "print(\"Generating headlines for test articles...\")\n",
    "generated_headlines = generate_headlines(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    articles=test_articles,\n",
    "    max_length=128,\n",
    "    num_beams=5\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated vs True Headlines:\")\n",
    "print(\"=\" * 100)\n",
    "for i, (article, true_headline, generated_headline) in enumerate(\n",
    "    zip(test_articles, true_headlines, generated_headlines)\n",
    "):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Article: {article[:150]}...\")\n",
    "    print(f\"True headline: {true_headline}\")\n",
    "    print(f\"Generated headline: {generated_headline}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with custom articles\n",
    "custom_articles = [\n",
    "    \"The stock market reached an all-time high today as investors showed confidence in the technology sector. Major tech companies reported strong quarterly earnings, driving the NASDAQ index up by 3.2%.\",\n",
    "    \"Scientists at MIT have developed a new type of battery that can charge electric vehicles in under 5 minutes. The breakthrough technology uses a novel lithium-metal composition that promises to revolutionize the EV industry.\",\n",
    "    \"The World Health Organization announced new guidelines for global pandemic preparedness following lessons learned from COVID-19. The recommendations include improved early warning systems and international cooperation protocols.\"\n",
    "]\n",
    "\n",
    "print(\"Testing model with custom articles...\")\n",
    "custom_headlines = generate_headlines(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    articles=custom_articles,\n",
    "    max_length=64,\n",
    "    num_beams=3\n",
    ")\n",
    "\n",
    "print(\"\\nCustom Article Headlines:\")\n",
    "print(\"=\" * 80)\n",
    "for i, (article, headline) in enumerate(zip(custom_articles, custom_headlines)):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Article: {article}\")\n",
    "    print(f\"Generated headline: {headline}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push to Hugging Face Hub (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell to push the model to Hugging Face Hub\n",
    "# Make sure you're logged in to Hugging Face Hub first\n",
    "\n",
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()\n",
    "\n",
    "# from src.training_utils import push_to_hub\n",
    "\n",
    "# hub_model_name = training_config[\"hub_model_name\"]\n",
    "# print(f\"Pushing model to Hugging Face Hub as: {hub_model_name}\")\n",
    "\n",
    "# try:\n",
    "#     push_to_hub(model, tokenizer, hub_model_name)\n",
    "#     print(\"Model successfully pushed to Hub!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Failed to push to hub: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with Different Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training experiment with different parameters\n",
    "quick_config = {\n",
    "    \"output_dir\": \"./models/headline-generator-quick\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"gradient_accumulation_steps\": 64,  # Reduced for faster training\n",
    "    \"learning_rate\": 1.0e-04,  # Higher learning rate\n",
    "    \"lora_r\": 32,  # Smaller LoRA rank\n",
    "    \"max_length\": 128,  # Shorter sequences\n",
    "}\n",
    "\n",
    "print(\"Running quick training experiment...\")\n",
    "print(\"Quick training configuration:\")\n",
    "for key, value in quick_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Uncomment to run quick training\n",
    "# trainer_quick, metrics_quick = quick_train(**quick_config)\n",
    "# print(f\"Quick training metrics: {metrics_quick}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Data Loading and Analysis**: How to load and explore the headline generation dataset\n",
    "2. **Modular Training**: Using the structured training pipeline with configurable parameters\n",
    "3. **Model Testing**: Testing the trained model with both validation data and custom examples\n",
    "4. **Hub Integration**: Optional pushing to Hugging Face Hub for sharing\n",
    "\n",
    "### Potential Next Steps:\n",
    "\n",
    "- **Hyperparameter Tuning**: Experiment with different learning rates, LoRA parameters, and training schedules\n",
    "- **Data Augmentation**: Try different data preprocessing techniques\n",
    "- **Model Comparison**: Train multiple models with different base architectures\n",
    "- **Evaluation Metrics**: Implement more comprehensive evaluation (ROUGE, BLEU, human evaluation)\n",
    "- **Deployment**: Integrate the trained model into the Streamlit app\n",
    "\n",
    "### Configuration Files:\n",
    "\n",
    "For production use, consider creating configuration files (YAML/JSON) to manage training parameters instead of hardcoding them in notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}